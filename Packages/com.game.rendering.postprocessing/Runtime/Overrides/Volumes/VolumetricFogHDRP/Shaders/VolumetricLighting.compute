//--------------------------------------------------------------------------------------------------
// Definitions
//--------------------------------------------------------------------------------------------------

// #pragma enable_d3d11_debug_symbols
#pragma only_renderers d3d11 playstation xboxone xboxseries vulkan metal switch

#pragma kernel VolumetricLighting
#pragma multi_compile _ ENABLE_REPROJECTION
#pragma multi_compile _ VL_PRESET_OPTIMAL
#pragma multi_compile _ _MAIN_LIGHT_SHADOWS _MAIN_LIGHT_SHADOWS_CASCADE _MAIN_LIGHT_SHADOWS_SCREEN
#pragma multi_compile _ _ADDITIONAL_LIGHTS
#pragma multi_compile _ _ADDITIONAL_LIGHT_SHADOWS
#pragma multi_compile_fragment _ _SHADOWS_SOFT _SHADOWS_SOFT_LOW _SHADOWS_SOFT_MEDIUM _SHADOWS_SOFT_HIGH 


// Don't want contact shadows
#define LIGHT_EVALUATION_NO_CONTACT_SHADOWS // To define before LightEvaluation.hlsl
// #define LIGHT_EVALUATION_NO_HEIGHT_FOG

#ifndef LIGHTLOOP_DISABLE_TILE_AND_CLUSTER
    #define USE_BIG_TILE_LIGHTLIST
#endif

#ifdef VL_PRESET_OPTIMAL
    // E.g. for 1080p: (1920/8)x(1080/8)x(64) = 2,073,600 voxels
    #define VBUFFER_VOXEL_SIZE 8
#endif

#define PREFER_HALF             0
#define GROUP_SIZE_1D           8
#define SHADOW_USE_DEPTH_BIAS   0 // Too expensive, not particularly effective
#define PUNCTUAL_SHADOW_ULTRA_LOW  // Different options are too expensive.
#define DIRECTIONAL_SHADOW_ULTRA_LOW  // Different options are too expensive.
#define AREA_SHADOW_LOW           // Different options are too expensive.
#define SHADOW_AUTO_FLIP_NORMAL 0 // No normal information, so no need to flip
#define SHADOW_VIEW_BIAS        1 // Prevents light leaking through thin geometry. Not as good as normal bias at grazing angles, but cheaper and independent from the geometry.
#define USE_DEPTH_BUFFER        1 // Accounts for opaque geometry along the camera ray
#define SAMPLE_PROBE_VOLUMES    1 && (defined(PROBE_VOLUMES_L1) || defined(PROBE_VOLUMES_L2))

#define SHADOW_DATA_NOT_GUARANTEED_SCALAR // We are not looping over shadows in a scalarized fashion. If we will at some point, remove this define.

//--------------------------------------------------------------------------------------------------
// Included headers
//--------------------------------------------------------------------------------------------------

// We need to include this "for reasons"...
//#include "Packages/com.unity.render-pipelines.high-definition/Runtime/Material/Builtin/BuiltinData.hlsl"

//#include "Packages/com.unity.render-pipelines.high-definition/Runtime/ShaderLibrary/ShaderVariables.hlsl"
//#include "Packages/com.unity.render-pipelines.high-definition/Runtime/RenderPipeline/ShaderPass/ShaderPass.cs.hlsl"
#define SHADERPASS SHADERPASS_VOLUMETRIC_LIGHTING

#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Common.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Color.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/GeometricTools.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/VolumeRendering.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/SphericalHarmonics.hlsl"
#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"
//#include "Packages/com.unity.render-pipelines.high-definition/Runtime/ShaderLibrary/ShaderVariables.hlsl"
//#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl"
//#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/ShaderVariablesFunctions.hlsl"
#include "../ShaderLibrary/VolumetricLighting/VolumetricGlobalParams.cs.hlsl"
#include "../ShaderLibrary/VolumetricLighting/VolumetricLighting.cs.hlsl"
#include "../ShaderLibrary/VolumetricLighting/GeometryUtils.cs.hlsl"
#include "../ShaderLibrary/VolumetricLighting/VolumetricCommonFunctions.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/UnityInstancing.hlsl" 
//#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/DeclareDepthTexture.hlsl"
#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/Random.hlsl"
//#include "Packages/com.unity.render-pipelines.core/ShaderLibrary/VolumeRendering.hlsl"
#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Lighting.hlsl"
// #include "Packages/com.unity.render-pipelines.universal/Runtime/Extensions/HotFix/Features/VolumetricFog/ShaderLibrary/VolumetricLighting/VoxelRealtimeLights.hlsl"
//#include "Packages/com.unity.render-pipelines.universal/Shaders/Utils/StencilDeferred.hlsl"
// #include "Packages/com.unity.render-pipelines.universal/Runtime/Extensions/HotFix/Features/VolumetricFog/ShaderLibrary/VolumetricLighting/VBuffer.hlsl"
//--------------------------------------------------------------------------------------------------
// Inputs & outputs
//--------------------------------------------------------------------------------------------------

RW_TEXTURE3D(float4, _VBufferLighting);
RW_TEXTURE3D(float4, _VBufferFeedback);
TEXTURE3D(_VBufferHistory);
TEXTURE3D(_VBufferDensity);                     // RGB = scattering, A = extinction
TEXTURE2D_X(_MaxZMaskTexture);
StructuredBuffer<float4> _VolumetricAmbientProbeBuffer;

float _AdditnalLightEnable[MAX_VISIBLE_LIGHTS]; 
float _AdditnalLightMultiplier[MAX_VISIBLE_LIGHTS]; 
float _AdditnalLightShadowDimmer[MAX_VISIBLE_LIGHTS]; 
float _AdditnalLightUseShadow[MAX_VISIBLE_LIGHTS];

float _MainLightEnable;
float _MainLightMultiplier;
float _MainLightShadowDimmer;

float _VolumetricNearPlane;
uint4 _LightingGroupSize;
uint _AdditnalLightCount;

#ifdef ENABLE_REPROJECTION
float4 _PrevCamPosRWS;
float4x4 UNITY_MATRIX_PREV_VP;
#endif
//--------------------------------------------------------------------------------------------------
// Implementation
//--------------------------------------------------------------------------------------------------

float3 GetViewUpDir()
{
    float4x4 viewMat = GetWorldToViewMatrix();
    return viewMat[1].xyz;
}

// Ambient probe for volumetric contains a convolution with Cornette Shank phase function so it needs to sample a different buffer.
real3 EvaluateVolumetricAmbientProbe(real3 normalWS)
{
#if SAMPLE_PROBE_VOLUMES // If we sample APV, ambient is baked in into APV and fallback into ambient is included in the APV sample.
    return 0;
#else
    real4 SHCoefficients[7];
    SHCoefficients[0] = _VolumetricAmbientProbeBuffer[0];
    SHCoefficients[1] = _VolumetricAmbientProbeBuffer[1];
    SHCoefficients[2] = _VolumetricAmbientProbeBuffer[2];
    SHCoefficients[3] = _VolumetricAmbientProbeBuffer[3];
    SHCoefficients[4] = _VolumetricAmbientProbeBuffer[4];
    SHCoefficients[5] = _VolumetricAmbientProbeBuffer[5];
    SHCoefficients[6] = _VolumetricAmbientProbeBuffer[6];

    return SampleSH9(SHCoefficients, normalWS);
#endif
}

// Jittered ray with screen-space derivatives.
struct JitteredRay
{
    float3 originWS;
    float3 centerDirWS;
    float3 jitterDirWS;
    float3 xDirDerivWS;
    float3 yDirDerivWS;
    float  geomDist;

    float maxDist;
};

struct BuiltinData
{
    real opacity;
    real alphaClipTreshold;
    real3 bakeDiffuseLighting;
    real3 backBakeDiffuseLighting;
    real shadowMask0;
    real shadowMask1;
    real shadowMask2;
    real shadowMask3;
    real3 emissiveColor;
    real2 motionVector;
    real2 distortion;
    real distortionBlur;
    uint isLightmap;
    uint renderingLayers;
    float depthOffset;
};

struct VoxelLighting
{
    float3 radianceComplete;
    float3 radianceNoPhase;
};



bool IsInRange(float x, float2 range)
{
    return clamp(x, range.x, range.y) == x;
}

float ComputeHistoryWeight()
{    
    float numFrames     = 7;
    float frameWeight   = 1 / numFrames;
    float historyWeight = 1 - frameWeight;

    return historyWeight;
}

VoxelLighting ComputeVoxelLightingDirectional(uint featureFlags, PositionInputs posInput, float3 centerWS,JitteredRay ray, float t0, float t1, float dt, float rndVal, float extinction, float anisotropy)
{
    VoxelLighting lighting;
    ZERO_INITIALIZE(VoxelLighting, lighting);
    BuiltinData unused; // Unused for now, so define once
    ZERO_INITIALIZE(BuiltinData, unused);

    const float NdotL = 1;

    float tOffset, weight;
    ImportanceSampleHomogeneousMedium(rndVal, extinction, dt, tOffset, weight);
    float t = t0 + tOffset;
    //ray.jitterDirWS
    posInput.positionWS = ray.originWS + t * ray.jitterDirWS * 0.5;
    //posInput.positionWS.xz = -posInput.positionWS.xz;
    //posInput.positionWS.y = -posInput.positionWS.y;
    //float3 nowPos = float3(-posInput.positionWS.x , posInput.positionWS.y , -posInput.positionWS.z);

    float4 shadowCoord = TransformWorldToShadowCoord(posInput.positionWS);
    Light mainLight = GetMainLight(shadowCoord);

    if(_MainLightShadowDimmer > 0)
    {
        half4 lightColor = float4(mainLight.color.rgb , 1) ;
        lightColor.rgb *= lightColor.a * _MainLightMultiplier;
        lightColor.rgb *= lerp(1 , mainLight.shadowAttenuation , _MainLightShadowDimmer) * _MainLightEnable;
        lighting.radianceComplete += weight * lightColor.rgb;
        lighting.radianceNoPhase += weight * lightColor.rgb;       
    }   
    return lighting;
}

VoxelLighting ComputeVoxelLightingAditional(uint featureFlags, PositionInputs posInput, float3 centerWS,JitteredRay ray, float t0, float t1, float dt, float rndVal, float extinction, float anisotropy)
{
    VoxelLighting lighting;
    ZERO_INITIALIZE(VoxelLighting, lighting);
    BuiltinData unused; // Unused for now, so define once
    ZERO_INITIALIZE(BuiltinData, unused);
    const float NdotL = 1;
    float tOffset, weight;
    ImportanceSampleHomogeneousMedium(rndVal, extinction, dt, tOffset, weight);
    float t = t0 + tOffset;
    //ray.jitterDirWS
    posInput.positionWS = ray.originWS + t * ray.jitterDirWS * 0.5;
    uint pixelLightCount = 0;
    pixelLightCount = _AdditnalLightCount;

#if defined(_ADDITIONAL_LIGHTS)
    LIGHT_LOOP_BEGIN(pixelLightCount)
    //Light light = GetAdditionalLight(lightIndex, posInput.positionWS);
    Light light = GetAdditionalPerObjectLight(lightIndex, posInput.positionWS);
    half realtimeShadow = 1;
    #ifdef _ADDITIONAL_LIGHT_SHADOWS
        realtimeShadow = AdditionalLightRealtimeShadow(lightIndex, posInput.positionWS, light.direction);
        realtimeShadow = lerp(1 , realtimeShadow , _AdditnalLightUseShadow[lightIndex]);
    #endif
    light.shadowAttenuation = realtimeShadow;
    half4 lightColor = half4(light.color.rgb , 1);
    lightColor.rgb *= lightColor.a ;
    lightColor.rgb *= light.shadowAttenuation * light.distanceAttenuation * _AdditnalLightMultiplier[lightIndex] * _AdditnalLightEnable[lightIndex];
    lighting.radianceComplete += lightColor.rgb * weight;
    lighting.radianceNoPhase += lightColor.rgb * weight;       
    LIGHT_LOOP_END
#endif


    //lighting.radianceComplete += lightColor.rgb * weight;
    //lighting.radianceNoPhase += lightColor.rgb * weight;
    return lighting;
}

void FillVolumetricLightingBuffer(uint featureFlags , PositionInputs posInput,uint tileIndex, int groupIdx, JitteredRay ray, float tStart)                              
{
    float t0 = max(tStart, DecodeLogarithmicDepthGeneralized(0, _VBufferDistanceDecodingParams));
    float de = _VBufferRcpSliceCount; // Log-encoded distance between slices

    float3 totalRadiance = 0;
    float  opticalDepth  = 0;
    uint slice = 0;
    for (; slice < _VBufferSliceCount; slice++)
    {
        //posInput.positionSS = _LightingGroupSize.xy * 8  - voxelCoord;
        uint3 voxelCoord = uint3(posInput.positionSS, slice + _VBufferSliceCount * unity_StereoEyeIndex);

        float e1 = slice * de + de; // (slice + 1) / sliceCount
        float t1 = max(tStart, DecodeLogarithmicDepthGeneralized(e1, _VBufferDistanceDecodingParams));
        float tNext = t1;
        float dt = t1 - t0; // Is geometry-aware
        if(dt <= 0.0)
        {
            _VBufferLighting[voxelCoord] = 0;
#ifdef ENABLE_REPROJECTION
           _VBufferFeedback[voxelCoord] = 0;
#endif
            t0 = t1;
            continue;
        }

        // Accurately compute the center of the voxel in the log space. It's important to perform
        // the inversion exactly, since the accumulated value of the integral is stored at the center.
        // We will use it for participating media sampling, asymmetric scattering and reprojection.
        float  t = DecodeLogarithmicDepthGeneralized(e1 - 0.5 * de, _VBufferDistanceDecodingParams);
        float3 centerWS = ray.originWS + t * ray.centerDirWS;

        // Sample the participating medium at the center of the voxel.
        // We consider it to be constant along the interval [t0, t1] (within the voxel).
        uint3 densityUV = voxelCoord;  
        //densityUV.z = slice * slice * 0.001 + _VBufferSliceCount * unity_StereoEyeIndex;
        float4 density = LOAD_TEXTURE3D(_VBufferDensity, densityUV);

        float3 scattering = density.rgb;
        float  extinction = density.a * 2;
        float  anisotropy = 0;
        float perPixelRandomOffset = GenerateHashedRandomFloat(posInput.positionSS);

#ifdef ENABLE_REPROJECTION
        // This is a time-based sequence of 7 equidistant numbers from 1/14 to 13/14.
        // Each of them is the centroid of the interval of length 2/14.
        float rndVal = frac(perPixelRandomOffset + _VBufferSampleOffset.z);
#else
        float rndVal = frac(perPixelRandomOffset + 0.5);
#endif


        VoxelLighting aggregateLighting;
        ZERO_INITIALIZE(VoxelLighting, aggregateLighting);
        extinction = max(extinction, 0);

        {
            VoxelLighting lighting = ComputeVoxelLightingDirectional(featureFlags, posInput,centerWS, ray, t0, t1, dt, rndVal, extinction, anisotropy);
            aggregateLighting.radianceNoPhase  += lighting.radianceNoPhase;
            aggregateLighting.radianceComplete += lighting.radianceComplete;       
        }

        {
            VoxelLighting lighting = ComputeVoxelLightingAditional(featureFlags, posInput,centerWS, ray, t0, t1, dt, rndVal, extinction, anisotropy);
            aggregateLighting.radianceNoPhase  += lighting.radianceNoPhase;
            aggregateLighting.radianceComplete += lighting.radianceComplete;         
        }

#ifdef ENABLE_REPROJECTION
        float4 voxelValue           = float4(aggregateLighting.radianceNoPhase, extinction * dt);
        float4 linearizedVoxelValue = LinearizeRGBD(voxelValue);
        float4 normalizedVoxelValue = linearizedVoxelValue * rcp(dt);
        float4 normalizedBlendValue = normalizedVoxelValue;

        float4 reprojValue = SampleVBuffer(TEXTURE3D_ARGS(_VBufferHistory, sampler_LinearClamp),
                                           centerWS,
                                           _PrevCamPosRWS.xyz,
                                           UNITY_MATRIX_VP,//UNITY_MATRIX_PREV_VP,
                                           _VBufferPrevViewportSize,
                                           _VBufferHistoryViewportScale.xyz,
                                           _VBufferHistoryViewportLimit.xyz,
                                           _VBufferPrevDistanceEncodingParams,
                                           _VBufferPrevDistanceDecodingParams,
                                           false, false, true) * float4(1,1,1, 1);
         reprojValue.rgb *= 0.85; 
        //reprojValue.a = 1 -  reprojValue.a;
        bool reprojSuccess = (_VBufferHistoryIsValid.r != 0.0) && (reprojValue.a != 0.0);
        
        if (reprojSuccess)
        {
            // Perform temporal blending in the log space ("Pixar blend").
            normalizedBlendValue = lerp(normalizedVoxelValue, reprojValue  , ComputeHistoryWeight());            
        }
        
        // Store the feedback for the voxel.
        // TODO: dynamic lights (which update their position, rotation, cookie or shadow at runtime)
        // do not support reprojection and should neither read nor write to the history buffer.
        // This will cause them to alias, but it is the only way to prevent ghosting.
       //int3 feedBackVoxel = voxelCoord;
       //feedBackVoxel.z = _VBufferSliceCount - (slice + _VBufferSliceCount * unity_StereoEyeIndex);
        int3 feedBackVoxel = voxelCoord;
        feedBackVoxel.z = _VBufferSliceCount - (slice + _VBufferSliceCount * unity_StereoEyeIndex);
        _VBufferFeedback[feedBackVoxel] = clamp(normalizedBlendValue * float4(1,1,1, 1), 0, HALF_MAX);
        //_VBufferLighting[feedBackVoxel] = max(0, float4(reprojValue.xyz , 1));
        //normalizedBlendValue = reprojValue;
        float4 linearizedBlendValue = normalizedBlendValue * dt;
        float4 blendValue = DelinearizeRGBD(linearizedBlendValue);
#else
        float4 blendValue = float4(aggregateLighting.radianceNoPhase,  extinction * dt);
#endif

        float transmittance = TransmittanceFromOpticalDepth(opticalDepth);
        float phase = INV_FOUR_PI;
        totalRadiance += transmittance * scattering * (phase * blendValue.rgb);
        opticalDepth += 0.5 * blendValue.a;
        _VBufferLighting[voxelCoord] = max(0, LinearizeRGBD(float4(/*FastTonemap*/(totalRadiance), opticalDepth)));
        if (t0 * 0.99 > ray.maxDist)
        {
            break;
        }

        t0 = tNext;
    }

   for (; slice < _VBufferSliceCount; slice++)
    {
        uint3 voxelCoord = uint3(posInput.positionSS, slice + _VBufferSliceCount * unity_StereoEyeIndex);
        _VBufferLighting[voxelCoord] = 0;
#ifdef ENABLE_REPROJECTION
        _VBufferFeedback[voxelCoord] = 0;
#endif

    }
}


[numthreads(GROUP_SIZE_1D, GROUP_SIZE_1D, 1)]
void VolumetricLighting(uint3 dispatchThreadId : SV_DispatchThreadID,
                        uint2 groupId          : SV_GroupID,
                        uint2 groupThreadId    : SV_GroupThreadID,
                        int   groupIndex       : SV_GroupIndex)
{
    // UNITY_XR_ASSIGN_VIEW_INDEX(dispatchThreadId.z);

    uint2 groupOffset = groupId * GROUP_SIZE_1D;
    uint2 voxelCoord  = groupOffset + groupThreadId;
    uint2 nowCoord = (_LightingGroupSize.xy - float2(0.5 , 0.5)) * GROUP_SIZE_1D  - voxelCoord;
    //voxelCoord = GROUP_SIZE_1D.xx - voxelCoord;
    // Reminder: our voxels are sphere-capped right frustums (truncated right pyramids).
    // The curvature of the front and back faces is quite gentle, so we can use
    // the right frustum approximation (thus the front and the back faces are squares).
    // Note, that since we still rely on the perspective camera model, pixels at the center
    // of the screen correspond to larger solid angles than those at the edges.
    // Basically, sizes of front and back faces depend on the XY coordinate.
    // https://www.desmos.com/calculator/i3rkesvidk

    float3 F = GetViewForwardDir();
    float3 U = GetViewUpDir();
    float3 R = cross(F, U);

    float2 centerCoord = voxelCoord + float2(0.5, 0.5);
    // Compute a ray direction s.t. ViewSpace(rayDirWS).z = 1.
    float4x4 cvtw = _VBufferCoordToViewDirWS[unity_StereoEyeIndex];
    float3 rayDirWS       = mul(-float4(centerCoord, 1, 1), cvtw).xyz;
    //rayDirWS.y = -rayDirWS.y; 
    float3 rightDirWS     = cross(rayDirWS, U);
    float  rcpLenRayDir   = rsqrt(dot(rayDirWS, rayDirWS));
    float  rcpLenRightDir = rsqrt(dot(rightDirWS, rightDirWS));
    //rayDirWS.xz = -rayDirWS.xz;
    JitteredRay ray;
    ray.originWS    = _WorldSpaceCameraPos.xyz;
    //ray.originWS.xz = -ray.originWS.xz;
    //ray.originWS.y -= 30;
    //
    ray.centerDirWS = rayDirWS * rcpLenRayDir; // Normalize
    
    float FdotD = dot(F, ray.centerDirWS);
    float unitDistFaceSize = _VBufferUnitDepthTexelSpacing * FdotD * rcpLenRayDir;

    ray.xDirDerivWS = rightDirWS * (rcpLenRightDir * unitDistFaceSize); // Normalize & rescale
    ray.yDirDerivWS = cross(ray.xDirDerivWS, ray.centerDirWS); // Will have the length of 'unitDistFaceSize' by construction

#ifdef ENABLE_REPROJECTION
    float2 sampleOffset = _VBufferSampleOffset.xy;
#else
    float2 sampleOffset = 0;
#endif

    ray.jitterDirWS = normalize(ray.centerDirWS + sampleOffset.x * ray.xDirDerivWS
                                                + sampleOffset.y * ray.yDirDerivWS);
    //ray.jitterDirWS.xz = -ray.jitterDirWS.xz;

    float tStart = _VolumetricNearPlane / dot(ray.jitterDirWS, F);

    // We would like to determine the screen pixel (at the full resolution) which
    // the jittered ray corresponds to. The exact solution can be obtained by intersecting
    // the ray with the screen plane, e.i. (ViewSpace(jitterDirWS).z = 1). That's a little expensive.
    // So, as an approximation, we ignore the curvature of the frustum.
    uint2 pixelCoord = (uint2)((voxelCoord + 0.5 + sampleOffset) * _VBufferVoxelSize);

#ifdef VL_PRESET_OPTIMAL
    // The entire thread group is within the same light tile.
    uint2 tileCoord = groupOffset * VBUFFER_VOXEL_SIZE / 64;
#else
    // No compile-time optimizations, no scalarization.
    uint2 tileCoord = pixelCoord / 64;
#endif
    uint  tileIndex = tileCoord.x + _NumTileBigTileX * tileCoord.y;
    // This clamp is important as _VBufferVoxelSize can have float value which can cause en overflow (Crash on Vulkan and Metal)
    tileIndex = min(tileIndex, _NumTileBigTileX * _NumTileBigTileY);

    // Do not jitter 'voxelCoord' else. It's expected to correspond to the center of the voxel.
    PositionInputs posInput = GetPositionInput(voxelCoord, _VBufferViewportSize.zw, tileCoord);

    ray.geomDist = FLT_INF;
    ray.maxDist = FLT_INF;
/*#if USE_DEPTH_BUFFER
    float deviceDepth = LoadCameraDepth(pixelCoord);

    if (deviceDepth > 0) // Skip the skybox
    {
        // Convert it to distance along the ray. Doesn't work with tilt shift, etc.
        float linearDepth = LinearEyeDepth(deviceDepth, _ZBufferParams);
        ray.geomDist = linearDepth * rcp(dot(ray.jitterDirWS, F));

        float2 UV = posInput.positionNDC * _RTHandleScale.xy;

        // This should really be using a max sampler here. This is a bit overdilating given that it is already dilated.
        // Better to be safer though.
        float4 d = GATHER_RED_TEXTURE2D_X(_MaxZMaskTexture, s_point_clamp_sampler, UV) * rcp(dot(ray.jitterDirWS, F));
        ray.maxDist = max(Max3(d.x, d.y, d.z), d.w);
    }
#endif*/

    // TODO
    uint featureFlags     = 0xFFFFFFFF;

    //ApplyCameraRelativeXR(ray.originWS);

    FillVolumetricLightingBuffer(featureFlags, posInput, tileIndex, groupIndex, ray, tStart);
}
